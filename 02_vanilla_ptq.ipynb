{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8262d131",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import utils\n",
    "\n",
    "# Reload utils module\n",
    "importlib.reload(utils)\n",
    "\n",
    "# import \n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a11260",
   "metadata": {},
   "source": [
    "## Load Float Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2d53280",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ResNet18().to(device)\n",
    "model.load_state_dict(torch.load(\"resnet18_float32.pth\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2614f69",
   "metadata": {},
   "source": [
    "### MinMax Observer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34d0778f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MinMaxObserver:\n",
    "    def __init__(self):\n",
    "        self.min =float('inf')\n",
    "        self.max = float('-inf')\n",
    "    def __call__(self, x):\n",
    "        self.min = min(self.min, x.min().item())\n",
    "        self.max = max(self.max, x.max().item())\n",
    "    def get_scale_zp(self, symmetric=True):\n",
    "        if symmetric:\n",
    "            r = max(abs(self.min), self.max)\n",
    "            scale = r / 127 if r>0 else 1.0\n",
    "            return scale, 0\n",
    "        else:\n",
    "            scale = (self.max - self.min) / 255\n",
    "            zp = round(-self.min /scale)\n",
    "            return scale, zp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c234de18",
   "metadata": {},
   "source": [
    "### activation calibration by Hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "041ee0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "observers = {}\n",
    "def get_hook(name):\n",
    "    def hook(module, input, output):\n",
    "        if name not in observers:\n",
    "            observers[name] = MinMaxObserver()\n",
    "        observers[name](output.detach().cpu())\n",
    "    return hook\n",
    "\n",
    "# Resigter Hook after Conv, Linear, ReLU, BatchNorm\n",
    "for name, m in model.named_modules():\n",
    "    if isinstance(m, (nn.Conv2d, nn.Linear, nn.ReLU, nn.BatchNorm2d)):\n",
    "        m.register_forward_hook(get_hook(name))\n",
    "        #print(f'name: {name}, m: {m}')\n",
    "\n",
    "# Calibration (2048 images)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i, (x, _) in enumerate(calib_loader):\n",
    "        if i > 15: break # 2048 images\n",
    "        model(x.to(device))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b67d856",
   "metadata": {},
   "source": [
    "### Activation quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6bf25ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_scales = {}\n",
    "# after calibration, get scale and zero-point\n",
    "for name, obs in observers.items():\n",
    "    # Activation usually use asymmetric uint8 (0~255) quantization\n",
    "    scale, zp = obs.get_scale_zp(symmetric=False)\n",
    "    #print(f\" scale: {scale}, zp: {zp} for {name}\")\n",
    "    activation_scales[name] = (scale, zp.item() if torch.is_tensor(zp) else zp)\n",
    "\n",
    "def fake_quant_act(x, scale, zp):\n",
    "    # Asymmetric uint8 quantization\n",
    "    q_x = torch.clamp(torch.round(x/scale+zp), 0, 255)\n",
    "    return (q_x -zp) *scale\n",
    "\n",
    "# remove hooks\n",
    "for name, m in model.named_modules():\n",
    "    if isinstance(m, (nn.Conv2d, nn.Linear, nn.ReLU, nn.BatchNorm2d)):\n",
    "        m._forward_hooks.clear()\n",
    "\n",
    "# register quantization hooks for activations\n",
    "def get_quant_hook(name):\n",
    "    def hook(module, input, output):\n",
    "        if name in activation_scales:\n",
    "            scale, zp = activation_scales[name]\n",
    "            return fake_quant_act(output, scale, zp)\n",
    "        return output\n",
    "    return hook\n",
    "\n",
    "for name, m in model.named_modules():\n",
    "    if isinstance(m, (nn.Conv2d, nn.Linear, nn.ReLU, nn.BatchNorm2d)):\n",
    "        m.register_forward_hook(get_quant_hook(name))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72baa90e",
   "metadata": {},
   "source": [
    "### Weight quantization (symmetric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bfdce24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_scales = {}\n",
    "for name, p in model.named_parameters():\n",
    "    if 'weight' in name and p.dim() > 1: #except bias\n",
    "        obs = MinMaxObserver()\n",
    "        obs(p.data.cpu())\n",
    "        scale, _ = obs.get_scale_zp(symmetric=True)\n",
    "        weight_scales[name] = scale\n",
    "        q_w = torch.round(p.data / scale).clamp(-128, 127)\n",
    "        p.data = q_w * scale # dequantized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2e9ccc",
   "metadata": {},
   "source": [
    "### Print Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "402d92c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vanilla PTQ Accuracy: 99.26%\n",
      "Float Model Size: 44.76 MB\n",
      "Quantized Model Size (INT8) 11.23 MB\n",
      "Inference Time: 0.045 ms/image\n"
     ]
    }
   ],
   "source": [
    "print(f\"Vanilla PTQ Accuracy: {evaluate(model):.2f}%\")\n",
    "print(f\"Float Model Size: {get_float_model_size(model):.2f} MB\")\n",
    "print(f\"Quantized Model Size (INT8) {get_quantized_model_size(model, weight_scales):.2f} MB\")\n",
    "print(f\"Inference Time: {measure_inference_time(model):.3f} ms/image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09259ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
